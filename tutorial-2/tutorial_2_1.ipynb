{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83222013",
   "metadata": {},
   "source": [
    "# Perspective Projection: Distance Estimation\n",
    "\n",
    "## The Pinhole Camera Model\n",
    "In computer vision and robotics typically an idealized model of the camera is used - *the pinhole camera model*. Light from the scene passes through an infinitely small hole and an inverted image is projected onto the opposite site of the box. \n",
    "To facilitate the visualisation, it is assumed that the projected image is formed on an imaginary image plane in front of the projection center. Then, the image is not longer upside-down.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img height=\"300\" src=\"imgs/pinhole.png\">\n",
    "</p>\n",
    "\n",
    "## Perspective Projection\n",
    "While we are moving through the world, we only perceive a projection of the 3D world onto our eye's retina or the robot perceives a projection of the 3D world onto its camera sensor. This has the effect that object that are close appear larger on the projected picture plane than objects at greater distance. \n",
    "\n",
    "This tutorial will provide further insights into the relationship between distance and perceived object size. Knowing the size of an object in the real world, will allow us to calculate the absolut distance to that object. Which assumptions are made? How is the observed error distributed? The following assignment will guide you through analytical methods of distance estimation via perspective projection.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img height=\"300\" src=\"imgs/perspective.png\">\n",
    "</p>\n",
    "\n",
    "# Coding: Getting Started\n",
    "Before you get started you need to follow the descriptions of the Git-Repository and make sure that all required packages are properly installed. It is recommended to work in a virtual environment. Start your virtual environment **before** you launch this jupyter-notebook. Then you may need to change the kernel: *Kernel &rarr; Change kernel &rarr; venv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51364717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os \n",
    "import glob\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dff181",
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO_MODEL = './model/yolo_model.pt'\n",
    "FILE = '../../data/take0_17-05-34/2023-6-28_17-05-34-821/2023-6-28_17-06-35-343099.png'\n",
    "PATH = '../../data/take0_17-05-34/2023-6-28_17-05-34-821'\n",
    "PATH_CSV = '../../data/take0_17-05-34/take_2023-06-28_05-28-07_pm_clean_matched_robo-ordered.csv'\n",
    "ROBOTS = [\"ollie\", \"grace\", \"alan\", \"hermann\", \"kaethe\"]\n",
    "CAM_ROBOT = \"ollie\"\n",
    "DEVICE = \"cpu\"\n",
    "FILE_EXTENSION = \"*.png\"\n",
    "ROBOT_HEIGHT_M = 0.09\n",
    "FOCALLENGTH_PX = 528.695652\n",
    "CONFIDENCE = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5babafd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading YOLOv5 Model\n",
    "model_YOLO = torch.hub.load('ultralytics/yolov5', 'custom', path=YOLO_MODEL, verbose=False)\n",
    "model_YOLO.conf = CONFIDENCE\n",
    "model_YOLO.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f5bb9f",
   "metadata": {},
   "source": [
    "## Part 1.1: Projected Object Size and Distance\n",
    "\n",
    "The provided code automatically detects little Lego Robots in an image. For detection we use a fine-tuned YOLOv5 network that estimates bounding boxes, that each capture the rough dimensions of the projected object.\n",
    "Given the height of an object bounding box, the camera's focal length as well as the actual robot's height we compute the absolut distance between \"CAM_ROBOT\" and all visible robots in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7b5435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(box, focallength_px, robot_height_m):\n",
    "    \n",
    "    ####################################################\n",
    "    # TODO 1:\n",
    "    # please fill in the code to compute \n",
    "    # the distance from the bounding box height\n",
    "\n",
    "    distance = 0\n",
    "\n",
    "    ####################################################\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991c6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model_YOLO(FILE)\n",
    "\n",
    "bounding_boxes = res.xyxy[0][res.xyxy[0][:, 0].sort()[1]]\n",
    "image = cv2.imread(FILE)\n",
    "\n",
    "for box in bounding_boxes:\n",
    "\n",
    "    ####################################################\n",
    "    # TODO 1:\n",
    "    # please fill in the code to compute \n",
    "    # the distance from the bounding box height\n",
    "\n",
    "    distance = dist(box, FOCALLENGTH_PX, ROBOT_HEIGHT_M)\n",
    "    \n",
    "    ####################################################\n",
    "    \n",
    "    cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)\n",
    "    image_with_rectangle = cv2.rectangle(image, (int(box[0]), int(box[1])-20), (int(box[0]) + 70, int(box[1])), (255,255,255), -1)\n",
    "    img_drawn = cv2.putText(image, f\"Dist: {(distance):.3f}\", (int(box[0]), int(box[1] - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,0,0), 1, cv2.LINE_AA)\n",
    "    image_rgb = cv2.cvtColor(img_drawn, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# visualize frame with overlayed \n",
    "# bounding boxes and distance estimates\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(image_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a51658",
   "metadata": {},
   "source": [
    "## Part 1.2: Visualization\n",
    "\n",
    "... now let's run this code on several consequtive frames and visualize the relationship between object height and its distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cbb6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Pictures...\")\n",
    "\n",
    "file_pattern = os.path.join(PATH, FILE_EXTENSION)\n",
    "picture_files = glob.glob(file_pattern)\n",
    "picture_files.sort()\n",
    "\n",
    "print(\"Reading pictures...\")\n",
    "\n",
    "values = {}\n",
    "\n",
    "for i, file in enumerate(picture_files):\n",
    "\n",
    "    res = model_YOLO(file)\n",
    "    bounding_boxes = res.xyxy[0][res.xyxy[0][:, 0].sort()[1]]\n",
    "\n",
    "    for box in bounding_boxes:\n",
    "        \n",
    "        distance = dist(box, FOCALLENGTH_PX, ROBOT_HEIGHT_M)\n",
    "\n",
    "        values.setdefault(distance, []).append(box[3] - box[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4880940",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for dist in values:\n",
    "    for height in values[dist]:\n",
    "        x.append(height.item())\n",
    "        y.append(dist)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "\n",
    "plt.xlabel('Height of the bounding box (in pixel)')\n",
    "plt.ylabel('Distance (CMs)')\n",
    "plt.title('Plot of height and distance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e75f75",
   "metadata": {},
   "source": [
    "## Part 2.1: Evaluation\n",
    "\n",
    "Groudtruth robot poses were captured with a motion capture system for all robots visible in this data. Poses were saved in the provided .csv file. In this part of the tutorial let's anayse the observed error. How does this relate to the object's distance? What are possible causes of this error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26447341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of picture files in PATH\n",
    "file_pattern = os.path.join(PATH, FILE_EXTENSION)\n",
    "picture_files = glob.glob(file_pattern)\n",
    "picture_files.sort()\n",
    "\n",
    "# read csv file with ground truth robot poses\n",
    "df = pd.read_csv(PATH_CSV, header=None)\n",
    "\n",
    "# get column for each robot in csv file\n",
    "row = df.iloc[0].to_numpy()\n",
    "robot_col = {}\n",
    "for rbo in ROBOTS:\n",
    "    bool_array = row == rbo\n",
    "    robot_col[rbo] = bool_array.argmax()\n",
    "cam_robot_col = robot_col[CAM_ROBOT]\n",
    "\n",
    "err = []\n",
    "distance_x = []\n",
    "\n",
    "for i, file in enumerate(picture_files):\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # LOAD GROUNDTRUTH DISTANCES FOR EACH PICTURE\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    row_val = os.path.basename(file)\n",
    "    row_matching_value = df[df.iloc[:, 0] == row_val]\n",
    "    print(\"********\")\n",
    "    print(row_val)\n",
    "\n",
    "    if row_matching_value.empty:\n",
    "        print(\"Skipping, since no matching image name in csv\")\n",
    "        continue\n",
    "\n",
    "    row = row_matching_value.index[0]\n",
    "\n",
    "    if type(df.at[row,2]) is not str and math.isnan(df.at[row,2]):\n",
    "        print(\"Skipping, since no robots visable on image \")\n",
    "        continue\n",
    "       \n",
    "    # robots present in current frame\n",
    "    robot_list = df.at[row,2].split()\n",
    "    \n",
    "    distance_gt = []\n",
    "    \n",
    "    for robot in zip(robot_list):\n",
    "        \n",
    "        # pose of the camera robot\n",
    "        camX = df.at[row,cam_robot_col+2]\n",
    "        camY = df.at[row,cam_robot_col]\n",
    "\n",
    "        # pose of neighboring robot\n",
    "        robotX = df.at[row, robot_col[robot[0]] + 2]\n",
    "        robotY = df.at[row, robot_col[robot[0]]]\n",
    "\n",
    "        # GROUNDTRUTH DISTANCE\n",
    "        distance = np.sqrt((float(robotX)-float(camX)) ** 2 + (float(robotY)-float(camY)) ** 2)\n",
    "        distance = distance / 100\n",
    "        \n",
    "        print(f\"distance_gt: {distance}\")\n",
    "        \n",
    "        distance = torch.tensor(distance, dtype = torch.float32,)\n",
    "        distance_gt.append(distance)\n",
    "        \n",
    "    # -----------------------------------------------------------------\n",
    "    # COMPUTE DISTANCE FROM BOUNDING BOX HEIGHT\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    res = model_YOLO(file)\n",
    "    bounding_boxes = res.xyxy[0][res.xyxy[0][:, 0].sort()[1]]\n",
    "\n",
    "    distance_estim = []\n",
    "    \n",
    "    for box in bounding_boxes:\n",
    "        \n",
    "        bbh = box[3] - box[1]\n",
    "        distance = FOCALLENGTH_PX * ROBOT_HEIGHT_M / bbh\n",
    "        distance_estim.append(distance)\n",
    "        \n",
    "        print(f\"distance_estim: {distance}\")\n",
    "        \n",
    "    # -----------------------------------------------------------------\n",
    "    # COMPUTE ERROR\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    if(bounding_boxes.shape[0] == len(robot_list)):\n",
    "\n",
    "        error = abs(np.array(distance_gt) - np.array(distance_estim))\n",
    "        err.extend(error)\n",
    "        distance_x.extend(distance_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb6127c",
   "metadata": {},
   "source": [
    "## Part 2.2: Visualization\n",
    "...now let's visualize again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f616b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(distance_x, err, label='Error')\n",
    "mean_err = np.mean(err)\n",
    "plt.axhline(y=mean_err, color='r', linestyle='--', label=f'Mean Error: {mean_err:.2f} m')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Distance [m]')\n",
    "plt.ylabel('Error [cm]')\n",
    "\n",
    "# Display the plot\n",
    "plt.legend()\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b213b",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "Please describe the behavior of the error. What are possible causes for errors that you observe? (Please name at least three causes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ccf9a",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
